"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸŒ¹ SENORITA VOICE AI â€” TEST & DEMO SCRIPT          â•‘
â•‘  Runs against a live backend, tests all endpoints + voice AI â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Usage (backend must be running first):
  python test_voice_ai.py

Modes available in this script:
  1. HTTP Health Check  â€” tests all REST endpoints
  2. Text Command       â€” send a typed command through the full WS pipeline
  3. Voice Command (Mic)â€” record your voice and send through the full WS pipeline
  4. Continuous Convo   â€” live multi-turn conversation with barge-in support

Extra dep for Test 4 playback:
  pip install pydub
  (also needs ffmpeg on PATH for MP3 decoding)
"""

import asyncio
import json
import sys
import time
import threading
import tempfile
import os
import io
import wave

import httpx
import websockets
import numpy as np

# â”€â”€ ANSI color codes for rich terminal output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RESET   = "\033[0m"
BOLD    = "\033[1m"
RED     = "\033[91m"
GREEN   = "\033[92m"
YELLOW  = "\033[93m"
BLUE    = "\033[94m"
MAGENTA = "\033[95m"
CYAN    = "\033[96m"
WHITE   = "\033[97m"
DIM     = "\033[2m"

# â”€â”€ Backend config (change if running on different host/port) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_URL    = "http://localhost:8000"
WS_URL      = "ws://localhost:8000/ws/voice"
SAMPLE_RATE = 16000   # Hz â€” matches what Deepgram expects
CHANNELS    = 1       # Mono
RECORD_SECS = 5       # Default recording duration


def log(prefix: str, color: str, message: str):
    """Colored, timestamped log line"""
    ts = time.strftime("%H:%M:%S")
    print(f"{DIM}[{ts}]{RESET} {color}{BOLD}{prefix:<14}{RESET}{WHITE}{message}{RESET}")


def section(title: str):
    """Prints a visual section separator"""
    width = 62
    print(f"\n{CYAN}{'â”€' * width}{RESET}")
    print(f"{CYAN}{BOLD}  {title}{RESET}")
    print(f"{CYAN}{'â”€' * width}{RESET}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  PART 1 â€” HTTP REST ENDPOINT TESTS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def test_http_endpoints():
    """Tests all REST API endpoints and prints results"""
    section("1/3  HTTP REST Endpoint Tests")

    async with httpx.AsyncClient(base_url=BASE_URL, timeout=10.0) as client:

        # Root
        log("GET /", GREEN, "Testing root endpoint...")
        try:
            r = await client.get("/")
            data = r.json()
            log("âœ… Root", GREEN, f"status={r.status_code}  response={data}")
        except Exception as e:
            log("âŒ Root", RED, f"FAILED: {e}")

        # Health
        log("GET /health", GREEN, "Testing health endpoint...")
        try:
            r = await client.get("/health")
            log("âœ… Health", GREEN, f"status={r.status_code}  response={r.json()}")
        except Exception as e:
            log("âŒ Health", RED, f"FAILED: {e}")

        # Status
        log("GET /api/status", GREEN, "Testing component status endpoint...")
        try:
            r = await client.get("/api/status")
            data = r.json()
            groq_ok    = data.get("groq",     {}).get("ok")
            dg_ok      = data.get("deepgram", {}).get("ok")
            stt_model  = data.get("deepgram", {}).get("stt_model")
            tts_voice  = data.get("deepgram", {}).get("tts_voice")
            log("âœ… Status", GREEN, f"Groq={groq_ok} | DG_ok={dg_ok} | STT={stt_model} | TTS={tts_voice}")
        except Exception as e:
            log("âŒ Status", RED, f"FAILED: {e}")

        # Voices
        log("GET /api/voices", GREEN, "Testing available TTS voices endpoint...")
        try:
            r = await client.get("/api/voices")
            voices = r.json()
            names = [v["name"] for v in voices]
            log("âœ… Voices", GREEN, f"Available: {', '.join(names)}")
        except Exception as e:
            log("âŒ Voices", RED, f"FAILED: {e}")

        # TTS via REST
        log("POST /api/tts", GREEN, "Testing TTS audio generation (REST)...")
        try:
            r = await client.post("/api/tts", json={"text": "Hello, I am Senorita. The voice AI is working correctly."})
            if r.status_code == 200:
                size_kb = len(r.content) / 1024
                log("âœ… TTS REST", GREEN, f"Audio received: {size_kb:.1f} KB  content-type={r.headers.get('content-type')}")
                # Save to temp so user can open and listen
                tts_file = os.path.join(tempfile.gettempdir(), "senorita_test_tts.mp3")
                with open(tts_file, "wb") as f:
                    f.write(r.content)
                log("   Saved â†’", YELLOW, f"{tts_file}")
            else:
                log("âŒ TTS REST", RED, f"status={r.status_code} body={r.text[:200]}")
        except Exception as e:
            log("âŒ TTS REST", RED, f"FAILED: {e}")

        # Text Command via REST
        log("POST /api/command", GREEN, "Testing text command via REST...")
        try:
            r = await client.post("/api/command", json={
                "transcript": "explain what a Python generator is",
                "context": None
            }, timeout=20.0)
            data = r.json()
            action   = data.get("action")
            response = (data.get("llm_response") or "")[:120]
            log("âœ… Command", GREEN, f"action={action}")
            log("   LLMâ†’", MAGENTA, f"{response}...")
        except Exception as e:
            log("âŒ Command", RED, f"FAILED: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  PART 2 â€” WEBSOCKET: TEXT COMMAND FLOW
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def ws_text_command(command: str):
    """
    Sends a typed text command over the /ws/voice pipeline.
    Shows every server event in real-time so you can see the
    full transcript â†’ action â†’ LLM â†’ TTS flow.
    """
    section(f"2/3  WebSocket Text Command Flow")
    log("Command", CYAN, f'"{command}"')

    try:
        async with websockets.connect(WS_URL) as ws:
            # â”€â”€ Wait for connected ack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            raw = await ws.recv()
            msg = json.loads(raw) if isinstance(raw, str) else None
            if msg:
                log("â†™ Server", GREEN, f'type={msg["type"]}  message={msg.get("message", "")}')

            # â”€â”€ Send text command â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            payload = json.dumps({"type": "text_command", "text": command})
            await ws.send(payload)
            log("â†— Sent", BLUE, f'type=text_command  text="{command}"')

            tts_audio_chunks = []

            # â”€â”€ Listen for all server events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            while True:
                try:
                    raw = await asyncio.wait_for(ws.recv(), timeout=30.0)
                except asyncio.TimeoutError:
                    log("â± Timeout", YELLOW, "No more messages received within 30s. Done.")
                    break

                if isinstance(raw, bytes):
                    # Binary = TTS audio bytes
                    tts_audio_chunks.append(raw)
                    log("â†™ Audio", MAGENTA, f"Received TTS audio chunk: {len(raw)} bytes")
                    continue

                try:
                    msg = json.loads(raw)
                except json.JSONDecodeError:
                    log("â†™ ???", RED, f"Non-JSON text: {raw[:100]}")
                    continue

                t = msg.get("type")

                if t == "action":
                    log("â†™ Action", CYAN, f'action={msg["action"]}  param="{msg.get("param", "")}"')

                elif t == "llm_chunk":
                    print(f"{MAGENTA}{msg['text']}{RESET}", end="", flush=True)

                elif t == "tts_start":
                    print()  # newline after streamed LLM text
                    log("â†™ TTS Start", YELLOW, "Server is generating audio...")

                elif t == "tts_done":
                    total_kb = sum(len(c) for c in tts_audio_chunks) / 1024
                    log("â†™ TTS Done", GREEN, f"Total TTS audio: {total_kb:.1f} KB")
                    if tts_audio_chunks:
                        mp3_bytes = b"".join(tts_audio_chunks)
                        # Try inline playback first
                        samples, sr = mp3_bytes_to_numpy(mp3_bytes)
                        if samples is not None:
                            try:
                                import sounddevice as sd
                                log("ğŸ”Š Playing", MAGENTA + BOLD, f"Playing {len(samples)/sr:.1f}s of audio...")
                                sd.play(samples, samplerate=sr)
                                sd.wait()   # block until done
                                log("âœ… Done", GREEN, "Playback complete")
                            except Exception as e:
                                log("âš  Playback", YELLOW, f"sounddevice error: {e}")
                        else:
                            audio_file = os.path.join(tempfile.gettempdir(), "senorita_ws_tts.mp3")
                            with open(audio_file, "wb") as f:
                                f.write(mp3_bytes)
                            log("   Saved â†’", YELLOW, f"{audio_file}  (pip install pydub + ffmpeg for live playback)")
                    break  # Flow complete

                elif t == "error":
                    log("â†™ Error", RED, f'{msg.get("message")}')
                    break

                elif t == "n8n_result":
                    log("â†™ n8n", CYAN, f'status={msg.get("status")}  action={msg.get("action")}')

                elif t == "instruction":
                    log("â†™ Instruction", CYAN, f'{msg.get("instruction")}')

                elif t == "pong":
                    log("â†™ Pong", DIM, "heartbeat ok")

                else:
                    log(f"â†™ {t}", DIM, str(msg))

    except websockets.ConnectionRefusedError:
        log("âŒ WS", RED, "Could not connect â€” is the backend running on port 8000?")
    except Exception as e:
        log("âŒ WS", RED, f"Error: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  PART 3 â€” WEBSOCKET: LIVE MICROPHONE VOICE FLOW
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def record_microphone(duration: int = RECORD_SECS, sample_rate: int = SAMPLE_RATE) -> bytes:
    """
    Records from the default microphone using sounddevice.
    Returns raw PCM bytes (int16, mono).
    """
    try:
        import sounddevice as sd
    except ImportError:
        log("âŒ Mic", RED, "sounddevice not installed. Run: pip install sounddevice")
        return b""

    log("ğŸ™ Record", YELLOW, f"Recording for {duration} seconds... SPEAK NOW!")
    audio = sd.rec(
        int(duration * sample_rate),
        samplerate=sample_rate,
        channels=CHANNELS,
        dtype="int16",
    )
    # Countdown
    for i in range(duration, 0, -1):
        print(f"\r{YELLOW}  â± {i}s remaining...{RESET}   ", end="", flush=True)
        time.sleep(1)
    sd.wait()
    print(f"\r{GREEN}  âœ… Recording complete!          {RESET}")

    # Convert numpy array to raw bytes â€” Deepgram expects int16 PCM
    return audio.tobytes()


async def ws_voice_command(duration: int = RECORD_SECS):
    """
    Records microphone audio, sends it to the /ws/voice endpoint
    as binary frames + end_audio signal, then prints all server events.
    
    This is the FULL voice pipeline test:
      mic â†’ binary WS frames â†’ STT â†’ command parser â†’ LLM â†’ TTS â†’ audio bytes back
    """
    section("3/3  WebSocket LIVE VOICE Flow (Mic Input)")
    log("Info", CYAN, f"Will record {duration}s of audio then send to backend STT...")
    log("Info", YELLOW, "Make sure your microphone is working and speak clearly!")

    # Record audio (blocking)
    audio_bytes = record_microphone(duration)
    if not audio_bytes:
        return

    log("Audio", BLUE, f"Captured {len(audio_bytes)} bytes of PCM audio")

    # Chunk size: 4096 bytes per frame â€” simulates real streaming
    CHUNK = 4096

    try:
        async with websockets.connect(WS_URL) as ws:
            # â”€â”€ Connected ack â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            raw = await ws.recv()
            msg = json.loads(raw) if isinstance(raw, str) else None
            if msg:
                log("â†™ Connected", GREEN, f'{msg.get("message", "")}')

            # â”€â”€ Stream binary audio in chunks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log("â†— Sending", BLUE, f"Streaming audio in {CHUNK}-byte chunks...")
            total_chunks = 0
            for i in range(0, len(audio_bytes), CHUNK):
                chunk = audio_bytes[i:i + CHUNK]
                await ws.send(chunk)   # Binary frame
                total_chunks += 1
            log("â†— Sent", GREEN, f"Streamed {total_chunks} audio chunks ({len(audio_bytes)} bytes total)")

            # Signal end of audio with PCM mimetype â€” tells backend to set encoding=linear16
            await ws.send(json.dumps({"type": "end_audio", "mimetype": "audio/pcm"}))
            log("â†— Sent", BLUE, "type=end_audio  mimetype=audio/pcm  â†’ Backend STT will use linear16 encoding")

            tts_audio_chunks = []

            # â”€â”€ Listen for all server events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            while True:
                try:
                    raw = await asyncio.wait_for(ws.recv(), timeout=40.0)
                except asyncio.TimeoutError:
                    log("â± Timeout", YELLOW, "No response in 40s. Done.")
                    break

                if isinstance(raw, bytes):
                    tts_audio_chunks.append(raw)
                    log("â†™ Audio", MAGENTA, f"TTS audio chunk: {len(raw)} bytes")
                    continue

                try:
                    msg = json.loads(raw)
                except json.JSONDecodeError:
                    continue

                t = msg.get("type")

                if t == "transcript":
                    log("â†™ Transcript", CYAN + BOLD, f'"{msg["text"]}"')

                elif t == "action":
                    log("â†™ Action", CYAN, f'action={msg["action"]}  param="{msg.get("param", "")}"')

                elif t == "llm_chunk":
                    print(f"{MAGENTA}{msg['text']}{RESET}", end="", flush=True)

                elif t == "tts_start":
                    print()
                    log("â†™ TTS Start", YELLOW, "Generating voice response...")

                elif t == "tts_done":
                    total_kb = sum(len(c) for c in tts_audio_chunks) / 1024
                    log("â†™ TTS Done", GREEN, f"Voice response: {total_kb:.1f} KB audio")
                    if tts_audio_chunks:
                        mp3_bytes = b"".join(tts_audio_chunks)
                        # Try inline playback first
                        samples, sr = mp3_bytes_to_numpy(mp3_bytes)
                        if samples is not None:
                            try:
                                import sounddevice as sd
                                log("ğŸ”Š Playing", MAGENTA + BOLD, f"Playing {len(samples)/sr:.1f}s of audio...")
                                sd.play(samples, samplerate=sr)
                                sd.wait()   # block until done
                                log("âœ… Done", GREEN, "Playback complete")
                            except Exception as e:
                                log("âš  Playback", YELLOW, f"sounddevice error: {e}")
                        else:
                            audio_file = os.path.join(tempfile.gettempdir(), "senorita_voice_response.mp3")
                            with open(audio_file, "wb") as f:
                                f.write(mp3_bytes)
                            log("   Saved â†’", YELLOW, f"{audio_file}  (pip install pydub + ffmpeg for live playback)")
                    break

                elif t == "error":
                    log("â†™ Error", RED, f'{msg.get("message")}')
                    break

                elif t == "instruction":
                    log("â†™ Instruction", CYAN, f'{msg.get("instruction")}')

                else:
                    log(f"â†™ {t}", DIM, str(msg))

    except websockets.ConnectionRefusedError:
        log("âŒ WS", RED, "Connection refused â€” is the backend running?")
    except Exception as e:
        log("âŒ WS", RED, f"Error: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  PART 4 â€” CONTINUOUS CONVERSATION WITH BARGE-IN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€ Barge-in config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BARGE_IN_THRESHOLD = 0.03   # RMS level (0.0â€“1.0) that triggers barge-in
BARGE_IN_CHUNK     = 512    # Samples per RMS check (~32ms at 16kHz)


def mp3_bytes_to_numpy(mp3_bytes: bytes, target_sr: int = 24000):
    """
    Decode MP3 bytes â†’ float32 mono numpy array using pydub.
    Falls back to None if pydub / ffmpeg not available.
    Returns (samples: np.ndarray, sample_rate: int) or (None, None).
    """
    try:
        from pydub import AudioSegment  # type: ignore
    except ImportError:
        return None, None
    try:
        seg = AudioSegment.from_mp3(io.BytesIO(mp3_bytes))
        seg = seg.set_frame_rate(target_sr).set_channels(1).set_sample_width(2)
        samples = np.frombuffer(seg.raw_data, dtype=np.int16).astype(np.float32) / 32768.0
        return samples, target_sr
    except Exception:
        return None, None


def play_with_barge_in(samples: np.ndarray, sr: int, barge_in_event: threading.Event) -> bool:
    """
    Plays audio samples via sounddevice while simultaneously monitoring the
    microphone for barge-in (user speaking).

    Returns True if barge-in was detected (caller should start new recording).
    Returns False if playback completed normally.

    How it works:
      - Playback runs on main thread via sd.play() (non-blocking)
      - A background thread captures mic frames and computes RMS
      - If RMS > BARGE_IN_THRESHOLD, sets barge_in_event and calls sd.stop()
      - Main thread polls both sd.get_status() and barge_in_event to detect end
    """
    try:
        import sounddevice as sd
    except ImportError:
        log("âŒ Audio", RED, "sounddevice not installed â€” install it to enable playback")
        # Still simulate by sleeping for audio duration
        time.sleep(len(samples) / sr)
        return False

    barge_detected = threading.Event()

    def mic_monitor():
        """Background thread: monitors mic for barge-in during playback"""
        try:
            with sd.InputStream(
                samplerate=SAMPLE_RATE,
                channels=1,
                dtype="float32",
                blocksize=BARGE_IN_CHUNK,
            ) as mic:
                while not barge_in_event.is_set() and not barge_detected.is_set():
                    chunk, _ = mic.read(BARGE_IN_CHUNK)
                    rms = float(np.sqrt(np.mean(chunk ** 2)))
                    if rms > BARGE_IN_THRESHOLD:
                        barge_detected.set()
                        barge_in_event.set()   # signal caller
                        sd.stop()              # kill playback immediately
                        log("ğŸ›‘ Barge-In!", RED + BOLD, f"Mic RMS={rms:.3f} > threshold={BARGE_IN_THRESHOLD} â€” stopping audio")
                        break
        except Exception:
            pass  # Monitor may fail if mic not available â€” just let playback finish

    monitor_thread = threading.Thread(target=mic_monitor, daemon=True)
    monitor_thread.start()

    # Start playback (non-blocking)
    sd.play(samples, samplerate=sr)

    # Wait until playback finishes OR barge-in fires
    while sd.get_stream().active and not barge_detected.is_set():
        time.sleep(0.05)

    barge_in_event.set()  # stop monitor thread if still running
    monitor_thread.join(timeout=1.0)
    return barge_detected.is_set()


async def ws_continuous_conversation(record_secs: int = 4):
    """
    Mode 4: Continuous multi-turn voice conversation with real barge-in.

    Pipeline per turn:
      1. ğŸ™ Record {record_secs}s of mic audio
      2. â†— Send WAV bytes to backend  /ws/voice
      3. â†™ Receive: transcript â†’ action â†’ LLM stream â†’ TTS audio chunks
      4. ğŸ”Š Play TTS audio while monitoring mic for barge-in
      5. If barge-in: immediately start next turn (step 1)
         If normal end: wait 0.5s then start next turn
      6. Loop until Ctrl+C or user says 'stop senorita'

    Barge-in:
      A background thread continuously reads the mic during playback.
      If mic RMS exceeds BARGE_IN_THRESHOLD, sd.stop() is called and
      recording immediately starts for the next turn.
    """
    section("4/4  CONTINUOUS CONVERSATION  (Ctrl+C to stop)")
    log("Info", CYAN,   f"Recording {record_secs}s per turn | Barge-in threshold={BARGE_IN_THRESHOLD}")
    log("Info", YELLOW, "TTS playback needs pydub+ffmpeg for audio. Install: pip install pydub")
    log("Info", DIM,    "Say 'stop senorita' to end the conversation.")
    print()

    try:
        import sounddevice as sd
        playback_available = True
    except ImportError:
        playback_available = False
        log("âš  Audio", YELLOW, "sounddevice not found â€” will show text only, no audio playback")

    turn = 0

    try:
        while True:
            turn += 1
            print(f"\n{CYAN}{BOLD}â”â”â” Turn {turn} {'â”' * 40}{RESET}")

            # â”€â”€ 1. Record â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            log(f"T{turn} ğŸ™ Record", YELLOW, f"Recording {record_secs}s â€” SPEAK NOW!")
            try:
                audio_np = sd.rec(
                    int(record_secs * SAMPLE_RATE),
                    samplerate=SAMPLE_RATE,
                    channels=CHANNELS,
                    dtype="int16",
                )
                for i in range(record_secs, 0, -1):
                    print(f"\r  {YELLOW}â± {i}s...{RESET}  ", end="", flush=True)
                    time.sleep(1)
                sd.wait()
                print(f"\r  {GREEN}âœ… Captured{RESET}           ")
            except Exception as e:
                log(f"T{turn} âŒ Mic", RED, f"Recording failed: {e}")
                break

            # Convert numpy int16 â†’ WAV bytes
            wav_buf = io.BytesIO()
            with wave.open(wav_buf, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)          # int16
                wf.setframerate(SAMPLE_RATE)
                wf.writeframes(audio_np.tobytes())
            wav_bytes = wav_buf.getvalue()
            log(f"T{turn} Audio", BLUE, f"WAV: {len(wav_bytes)} bytes â†’ sending to backend")

            # â”€â”€ 2. WebSocket: Send audio + receive full pipeline â”€â”€â”€â”€â”€â”€â”€
            tts_chunks: list[bytes] = []
            transcript_text = ""
            interrupted = False

            try:
                async with websockets.connect(WS_URL) as ws:
                    # Wait for connected ack
                    raw = await ws.recv()
                    if isinstance(raw, str):
                        ack = json.loads(raw)
                        log(f"T{turn} â†™ WS", GREEN, f'connected: {ack.get("message", "")}')

                    # Stream WAV in chunks
                    CHUNK = 4096
                    for i in range(0, len(wav_bytes), CHUNK):
                        await ws.send(wav_bytes[i:i + CHUNK])

                    # Signal end with WAV mimetype (auto-detected, no encoding kwarg needed)
                    await ws.send(json.dumps({"type": "end_audio", "mimetype": "audio/wav"}))
                    log(f"T{turn} â†— Sent", BLUE, "end_audio â€” waiting for STTâ€¦")

                    # Collect all events until tts_done or error
                    while True:
                        try:
                            raw = await asyncio.wait_for(ws.recv(), timeout=40.0)
                        except asyncio.TimeoutError:
                            log(f"T{turn} â±", YELLOW, "40s timeout waiting for response")
                            break

                        if isinstance(raw, bytes):
                            tts_chunks.append(raw)
                            continue

                        try:
                            msg = json.loads(raw)
                        except json.JSONDecodeError:
                            continue

                        t = msg.get("type")

                        if t == "transcript":
                            transcript_text = msg.get("text", "")
                            log(f"T{turn} â†™ STT", CYAN + BOLD, f'"{transcript_text}"')
                            # Stop-word detection
                            if any(w in transcript_text.lower() for w in ("stop senorita", "stop seniorita", "goodbye senorita")):
                                log(f"T{turn} ğŸ›‘ Stop", RED, "Stop word detected â€” ending conversation")
                                interrupted = True
                                break

                        elif t == "action":
                            log(f"T{turn} â†™ Action", CYAN, f'action={msg["action"]}  param="{msg.get("param", "")}"')

                        elif t == "llm_chunk":
                            print(f"{MAGENTA}{msg['text']}{RESET}", end="", flush=True)

                        elif t == "tts_start":
                            print()  # newline after LLM stream
                            log(f"T{turn} â†™ TTS", YELLOW, "Generating audio responseâ€¦")

                        elif t == "tts_done":
                            total_kb = sum(len(c) for c in tts_chunks) / 1024
                            log(f"T{turn} â†™ TTSâœ“", GREEN, f"Audio ready: {total_kb:.1f} KB")
                            break

                        elif t == "error":
                            log(f"T{turn} â†™ Err", RED, msg.get("message", ""))
                            break

            except websockets.ConnectionRefusedError:
                log(f"T{turn} âŒ", RED, "Connection refused â€” is the backend running?")
                break
            except Exception as e:
                log(f"T{turn} âŒ", RED, f"WS error: {e}")
                break

            if interrupted:
                break

            # â”€â”€ 3. Playback with barge-in â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if tts_chunks and playback_available:
                mp3_bytes = b"".join(tts_chunks)
                samples, sr = mp3_bytes_to_numpy(mp3_bytes)

                if samples is not None:
                    log(f"T{turn} ğŸ”Š Play", MAGENTA + BOLD, f"Playing {len(samples)/sr:.1f}s of audio (barge-in armed)â€¦")
                    barge_in_event = threading.Event()
                    barged_in = play_with_barge_in(samples, sr, barge_in_event)
                    if barged_in:
                        log(f"T{turn} ğŸ”", RED + BOLD, "Barge-in! Starting next turn immediatelyâ€¦")
                        continue   # skip the 0.5s pause and go straight to recording
                    else:
                        log(f"T{turn} âœ… Done", GREEN, "Playback complete â€” starting next turn in 0.5sâ€¦")
                else:
                    log(f"T{turn} âš  pydub", YELLOW, "Could not decode MP3 (pydub/ffmpeg missing). Text-only mode.")
                    mp3_file = os.path.join(tempfile.gettempdir(), f"senorita_turn_{turn}.mp3")
                    with open(mp3_file, "wb") as f:
                        f.write(mp3_bytes)
                    log(f"T{turn} Saved", DIM, f"Audio at: {mp3_file}")
            elif tts_chunks:
                # No sounddevice: save and continue
                mp3_file = os.path.join(tempfile.gettempdir(), f"senorita_turn_{turn}.mp3")
                with open(mp3_file, "wb") as f:
                    for c in tts_chunks:
                        f.write(c)
                log(f"T{turn} Saved", DIM, f"Audio at: {mp3_file} (install sounddevice + pydub for live playback)")

            time.sleep(0.5)   # Brief pause before next turn

    except KeyboardInterrupt:
        print(f"\n{YELLOW}Conversation ended by user (Ctrl+C).{RESET}")

    log("Done", GREEN, f"Conversation ended after {turn} turn(s).")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  INTERACTIVE MENU
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    print(f"""
{CYAN}{BOLD}â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸŒ¹ SENORITA VOICE AI â€” TEST & DEMO SCRIPT          â•‘
â•‘          Backend: {BASE_URL:<43}â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•{RESET}
""")

    while True:
        print(f"""
{BOLD}Select a test:{RESET}
  {GREEN}1{RESET} â€” HTTP REST endpoint suite (health, status, voices, TTS, command)
  {BLUE}2{RESET} â€” WebSocket text command (type a command, see full pipeline)
  {YELLOW}3{RESET} â€” WebSocket VOICE command (record mic â†’ STT â†’ LLM â†’ TTS)
  {MAGENTA}4{RESET} â€” {BOLD}CONTINUOUS CONVERSATION{RESET} ğŸ”„  (live multi-turn + barge-in)
  {RED}q{RESET} â€” Quit
""")
        choice = input(f"{BOLD}> {RESET}").strip().lower()

        if choice == "1":
            await test_http_endpoints()

        elif choice == "2":
            print(f"\n{BOLD}Enter your voice command (as text):{RESET}")
            print(f"  {DIM}Examples: 'explain what async await does in Python'{RESET}")
            print(f"  {DIM}          'debug this: def add(a,b): return a-b'{RESET}")
            print(f"  {DIM}          'create file utils.py'{RESET}")
            cmd = input(f"{BOLD}Command > {RESET}").strip()
            if cmd:
                await ws_text_command(cmd)

        elif choice == "3":
            print(f"\n{BOLD}How many seconds to record? {DIM}(default: 5){RESET}")
            secs_input = input(f"{BOLD}Seconds > {RESET}").strip()
            try:
                secs = int(secs_input) if secs_input else RECORD_SECS
                secs = max(2, min(secs, 30))  # clamp to 2â€“30s
            except ValueError:
                secs = RECORD_SECS
            await ws_voice_command(secs)

        elif choice == "4":
            print(f"\n{BOLD}Seconds per recording turn? {DIM}(default: 4, recommended 3-5){RESET}")
            secs_input = input(f"{BOLD}Seconds > {RESET}").strip()
            try:
                secs = int(secs_input) if secs_input else 4
                secs = max(2, min(secs, 15))
            except ValueError:
                secs = 4
            print(f"""
{MAGENTA}{BOLD}  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  CONTINUOUS CONVERSATION MODE                           â”‚
  â”‚  â€¢ Speak when you see ğŸ™  SPEAK NOW!                   â”‚
  â”‚  â€¢ Senorita will respond with voice                     â”‚
  â”‚  â€¢ Speak over her to interrupt (barge-in)               â”‚
  â”‚  â€¢ Say 'stop senorita' to end the conversation          â”‚
  â”‚  â€¢ Press Ctrl+C anytime to exit                         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜{RESET}
""")
            await ws_continuous_conversation(record_secs=secs)

        elif choice in ("q", "quit", "exit"):
            print(f"\n{GREEN}Goodbye! ğŸŒ¹{RESET}\n")
            break

        else:
            print(f"{RED}Unknown choice. Enter 1, 2, 3, 4 or q.{RESET}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print(f"\n{YELLOW}Interrupted. Goodbye!{RESET}\n")
